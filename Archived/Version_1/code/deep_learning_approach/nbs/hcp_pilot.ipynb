{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dictionaries\n",
    "import neuropythy as ny\n",
    "import ipyvolume as ipv\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = 'AKIAXO65CT57P5FICGUJ:H0xhEJuJJ0viUygH7gYkqJj58JsNx66JHFqnheQi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny.config['hcp_credentials'] = credentials\n",
    "fs = ny.data['hcp'].s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full path to T1w NIFTIs\n",
    "fid = fs.ls('hcp-openaccess/HCP_1200/')\n",
    "fid.pop(0)\n",
    "fpath = []\n",
    "for f in fid:\n",
    "    fpath.append(f +'/MNINonLinear/T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of subject IDs\n",
    "sid = []\n",
    "for f in fid:\n",
    "    sid.append(f.split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_array = np.array([], np.float32)\n",
    "sub = ny.hcp_subject(sid[0])\n",
    "im = sub.load('MNINonLinear/T1w.nii.gz')\n",
    "data = im.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 311, 260)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21023600,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.append(im_array, np.asanyarray(data))\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized_image = tf.image.resize_images(images=FA_data, size=(FLAGS.width,FLAGS.height), method=1)\n",
    "resized_image = tf.image.resize_images(images=data, size=(256, 256), method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bbf6bb90561f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "im_array = np.append(im_array, np.asarray(resized_image, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7efced0d3ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_image.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### def load_hcp_data(credentials, slice_number):\n",
    "\n",
    "    # Configure neuropythy\n",
    "    ny.config['hcp_credentials'] = credentials\n",
    "    fs = ny.data['hcp'].s3fs\n",
    "\n",
    "    # Get full path to T1w NIFTIs\n",
    "    fid = fs.ls('hcp-openaccess/HCP_1200/')\n",
    "    fid.pop(0)\n",
    "    fpath = []\n",
    "    for f in fid:\n",
    "        fpath.append(f +'/MNINonLinear/T1w.nii.gz')\n",
    "    \n",
    "    # Get list of subject IDs\n",
    "    sid = []\n",
    "    for f in fid:\n",
    "        sid.append(f.split('/')[2])\n",
    "\n",
    "    # Save single slice for each subject into concatenated array\n",
    "    im_array = []\n",
    "    sid_tmp = sid[0:3]\n",
    "    for i in sid_tmp:\n",
    "        print(i)\n",
    "        sub = ny.hcp_subject(i)\n",
    "        im = sub.load('MNINonLinear/T1w.nii.gz')\n",
    "        data = im.get_fdata()\n",
    "        im_array.append(data[:,:,slice_number])\n",
    "    \n",
    "    arr = np.asarray(im_array)\n",
    "    arr_padded = np.pad(img, [(0,0), (25,26), (0,0)], mode = 'constant') # hard coded to pad this dimension!\n",
    "    \n",
    "    return arr, sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
